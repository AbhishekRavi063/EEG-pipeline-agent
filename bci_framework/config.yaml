# BCI AutoML Platform v1.0 — Product-Grade Configuration
# No code changes required for switching parameters or adding new pipelines.

mode: "offline"  # offline | online (auto-disables non-causal steps in online)
task: "motor_imagery"  # used for adaptive bands (e.g. motor imagery 8–30 Hz)

dataset:
  name: "BCI_IV_2a"
  data_dir: "./data/BCI_IV_2a"
  download_if_missing: true
  subjects: [1, 2, 3, 4, 5, 6, 7, 8, 9]
  # Per-trial segment length (seconds). BCI IV 2a protocol uses 3 s motor imagery; set to 4 if you want longer segments (GDF must have enough data).
  trial_duration_seconds: 3
  evaluation_mode: "subject_wise"  # subject_wise | cross_subject | loso | cross_session
  # Research evaluation: scalp_space (baseline) | source_space (GeDai) | hybrid (comparison) | LOSO | cross_dataset (MOABB)
  research_evaluation_mode: "scalp_space"  # scalp_space | source_space | hybrid
  train_test_split: 0.8
  # IMPORTANT: For BCI IV 2a, use_cross_session_split: true prevents mixing T/E sessions
  # This avoids data leakage and suspiciously high accuracy (reviewers expect T/E split)
  use_cross_session_split: true  # Set true for T session (train) / E session (test) split (METHODOLOGICALLY CORRECT)
  # trial = 80/20 split; sequential = first N trials calibration, rest live stream (like real BCI)
  split_mode: "train_test"  # train_test | sequential
  stream_calibration_trials: 20  # for sequential: first N trials = pipeline selection, rest = stream
  split_level: "trial"  # trial | loso
  loso_holdout_subject: null  # set to subject id for LOSO
  # Streaming mode: "trial" (per-trial batch) or "sliding" (true sliding-window real-time)
  streaming_mode: "trial"  # "trial" | "sliding"

# Spatial filter layer (plugin): replaces reference when enabled (v3.1: strict/auto modes)
spatial_filter:
  enabled: true
  # car | laplacian | laplacian_strict | laplacian_auto | gedai_strict | gedai_auto | csp | gedai
  # Backward compat: "laplacian" -> laplacian_auto, "gedai" -> gedai_auto
  method: "laplacian_auto"
  motor_only: true
  leadfield_path: null
  laplacian_neighbours: null
  auto_select: true
  methods_for_automl: ["car", "laplacian", "csp"]

preprocessing:
  notch_freq: 50  # 60 for US
  notch_quality: 30
  bandpass_low: 0.5
  bandpass_high: 40
  bandpass_order: 5
  adaptive_motor_band: true  # if task == motor_imagery → use motor band below
  motor_band_low: 8
  motor_band_high: 30
  reference: "car"  # car | laplacian (used when spatial_filter.enabled is false)
  laplacian_neighbours: null  # optional mapping (channel->neighbours)

advanced_preprocessing:
  # Scientific order enforced: signal_quality -> gedai -> ica -> asr -> wavelet
  # GEDAI runs BEFORE ICA to improve source separation (physics-based denoising first)
  enabled: ["signal_quality", "gedai", "ica", "wavelet"]
  gedai:
    # Use a real leadfield (FreeSurfer/MNE). Identity is for testing only (otherwise ~PCA, no physics).
    leadfield_path: null   # path to .pt/.npy; generate: python -m bci_framework.preprocessing.forward_model
    use_identity_if_missing: false  # true = dev/test only (creator: identity makes no sense for real denoising)
    require_real_leadfield: true     # Enforce physics: fail if no leadfield (set false to allow identity fallback)
    mode: "batch"          # "batch" (offline) or "sliding" (online, causal, low-latency)
    window_sec: 10.0       # Sliding window duration (for mode="sliding")
    update_interval_sec: 1.0  # How often to recompute eigenvectors (for sliding mode)
    device: null           # "cpu", "cuda", "mps", or null (auto-detect GPU)
    cov_recompute_post_gedai: false  # For CSP compatibility (recompute covariance after GEDAI)
  signal_quality:
    variance_z: 5.0
    kurtosis_z: 5.0
    interpolate: true
  ica:
    n_components: 15
    max_iter: 500
  wavelet:
    wavelet: "db4"
    level: 4
  asr:
    cutoff: 20.0
    window_sec: 0.5

features:
  csp:
    n_components: 4
    use_cv_fitting: null  # null = auto (CV if n_trials < 30), true = always CV, false = never CV
    cv_folds: 5  # K-fold CV (or null for leave-one-trial-out if n_trials < 10)
  psd:
    fmin: 1
    fmax: 40
    n_fft: 256
  wavelet:
    wavelet: "db4"
    level: 4
  riemannian:
    n_components: 10

classifiers:
  lda: {}
  svm:
    C: 1.0
    kernel: "rbf"
    gamma: "scale"
  random_forest:
    n_estimators: 100
    max_depth: 10
  eegnet:
    n_classes: 4
    n_channels: 22
    samples: 1000  # 4 sec @ 250 Hz
    dropout: 0.25
  transformer: {}  # placeholder

pipelines:
  # Auto-generate combinations (feature × classifier), or list explicit [feature, classifier] pairs
  auto_generate: true
  max_combinations: 20  # cap for performance (M4 Pro 16GB)
  # Explicit pipelines: [["csp", "lda"], ["psd", "svm"], ...]
  explicit: []

# v3: Domain adaptation / transfer learning (offline, cross-subject only; no streaming)
# Contract: DA runs ONLY on (n_trials, n_features) after feature extraction. Never on raw EEG.
# For MI (e.g. BNCI2014_001): riemann_transport is preferred (low memory: 22×22 covariances).
transfer:
  enabled: false
  method: "none"   # none | zscore | coral | riemann_transport (prefer riemann_transport for MI)
  target_unlabeled_fraction: 0.2   # first N% of target trials as unlabeled adaptation (LOSO)
  regularization: 1e-3   # CORAL epsilon for numerical stability
  safe_mode: false   # true: CORAL dim cap 128, float32, skip adaptation if unsafe (8–16GB RAM)

# Calibration protocol: duration (trials), baseline evaluation, sliding-window adaptation
calibration:
  duration_trials: 50
  baseline_min_trials: 30
  sliding_window_adaptation: true

# Unified streaming: offline vs online (real-time)
streaming:
  mode: "offline"  # offline | online (online = real-time safe, precomputed filters only)
  window_size_sec: 1.0   # causal window for pipeline (1 s typical)
  overlap_sec: 0.5       # overlap between consecutive windows (0.5 = 50%)
  # Trial mode (per-trial batch) vs sliding (continuous)
  pipeline_mode: "trial"  # "trial" | "sliding"
  window_size_samples: null  # set from fs if null
  buffer_length_sec: 10.0  # Ring buffer (online/sliding)
  update_interval_sec: 0.1
  stream_full_test_set: true
  real_time_timing: true
  trial_duration_sec: 3.0

agent:
  calibration_trials: 50
  # v2: k-fold CV for pipeline ranking (use mean CV accuracy; reduces overfitting)
  cv_folds: 5
  overfit_penalty_weight: 0.2   # penalty for (train_accuracy - cv_accuracy) in composite score
  prefer_linear_models: true    # tie-break: prefer LDA / linear SVM
  # Online mode: first N trials for calibration, rest live stream
  calibration_window_trials: 5   # online: number of trials for initial calibration
  top_n_pipelines: 3
  trial_duration_sec: 3.0  # for ITR
  # Smart adaptive pruning (reduce compute; backward compatible if quick_screening missing)
  quick_screening:
    enabled: true
    subset_fraction: 0.25
    min_accuracy_threshold: 0.35
    max_pipelines_after_screening: 5
    ranking_metric: balanced_accuracy
    min_pipelines_to_keep: 3
    max_pipelines_to_keep: 6
    num_repeats: 2
    dynamic_top_k: true
    exclude_pipelines: ["gedai"]
    random_state: 42
  early_cv_stop: true
  progressive_halving:
    enabled: false
    reduction_factor: 2
  prune_thresholds:
    min_accuracy: 0.45
    min_accuracy_online: 0.5    # online calibration early pruning
    max_latency_ms: 500
    max_latency_ms_online: 300  # online calibration latency cap
    latency_budget_ms: 300      # product target: 100–300 ms
    max_stability_variance: 0.05
  re_evaluate_interval_trials: 100
  metrics:
    - "accuracy"
    - "kappa"
    - "itr_bits_per_minute"
    - "f1_macro"
    - "roc_auc_macro"
    - "latency"
    - "stability"
    - "confidence"
  drift:
    window_size: 20
    window_trials: 10           # rolling window for drift (alias: min trials in window)
    min_trials_for_drift: 10
    accuracy_drop_threshold: 0.15
    min_accuracy_absolute: 0.35
    min_accuracy_absolute_online: 0.6  # online: minimum acceptable accuracy
    consecutive_low_windows: 2
  hyperparameter_optimization:
    enabled: false
    backend: "optuna"  # optuna | grid
    n_trials: 20
    timeout_sec: 300
    # Default param ranges for out-of-the-box tuning (CSP, bandpass, LDA)
    param_ranges:
      bandpass_highcut: [30, 40]
      csp_n_components: [2, 4, 6]
      lda_shrinkage: [0.0, 0.5, 1.0]
      svm_C: [0.1, 1.0, 10.0]
      svm_gamma: ["scale", "auto"]

gui:
  refresh_rate_ms: 100
  eeg_channels_display: 8
  window_seconds: 4
  web_port: 8765  # port for --web UI; change if 8765 is in use (e.g. 8766)

logging:
  results_dir: "./results"
  save_snapshots: true
  save_all_pipelines: true  # selected and rejected
  save_model_checkpoints: true  # .pkl / .pt per pipeline
  snapshot_formats:
    - "png"
    - "json"
  versioned_experiments: true  # results/<experiment_id>/<pipeline_name>/

# Experiment tracking & reproducibility
experiment:
  seed: 42
  experiment_id: null  # auto if null
  mlflow:
    enabled: false
    tracking_uri: "./mlruns"
    experiment_name: "bci_automl"

# Compute: max pipelines in parallel (M4 Pro 16GB)
compute:
  max_parallel_pipelines: 5
  use_gpu: true  # PyTorch MPS/CUDA if available

# Future placeholders (extensibility)
future:
  real_eeg_hardware: null  # OpenBCI, Emotiv, LSL
  mcp_llm_integration: false
  cloud_training: false
  reinforcement_learning_selector: false
  federated_bci_learning: false
  human_in_the_loop_feedback: true
